{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "def extract_product_info(soup):\n",
        "    try:\n",
        "        title = soup.find(\"span\", attrs={\"id\": 'productTitle'}).text.strip().replace(',', '')\n",
        "    except AttributeError:\n",
        "        title = \"NA\"\n",
        "\n",
        "    try:\n",
        "        price = soup.find(\"span\", attrs={'id': 'priceblock_ourprice'}).text.strip().replace(',', '')\n",
        "    except AttributeError:\n",
        "        price = \"NA\"\n",
        "\n",
        "    try:\n",
        "        rating = soup.find(\"i\", attrs={'class': 'a-icon a-icon-star a-star-4-5'}).text.strip().replace(',', '')\n",
        "    except AttributeError:\n",
        "        try:\n",
        "            rating = soup.find(\"span\", attrs={'class': 'a-icon-alt'}).text.strip().replace(',', '')\n",
        "        except AttributeError:\n",
        "            rating = \"NA\"\n",
        "\n",
        "    try:\n",
        "        review_count = soup.find(\"span\", attrs={'id': 'acrCustomerReviewText'}).text.strip().replace(',', '')\n",
        "    except AttributeError:\n",
        "        review_count = \"NA\"\n",
        "\n",
        "    try:\n",
        "        available = soup.find(\"div\", attrs={'id': 'availability'}).find(\"span\").text.strip().replace(',', '')\n",
        "    except AttributeError:\n",
        "        available = \"NA\"\n",
        "\n",
        "    return title, price, rating, review_count, available\n",
        "\n",
        "def extract_reviews(soup):\n",
        "    reviews = soup.find_all(\"div\", class_=\"review\")\n",
        "\n",
        "    review_info = []\n",
        "    for review in reviews:\n",
        "        title_element = review.find(\"a\", class_=\"review-title\")\n",
        "        rating_element = review.find(\"span\", class_=\"review-rating\")\n",
        "        author_element = review.find(\"span\", class_=\"a-profile-name\")\n",
        "        date_element = review.find(\"span\", class_=\"review-date\")\n",
        "        body_element = review.find(\"div\", class_=\"review-text\")\n",
        "\n",
        "        title = title_element.text.strip() if title_element else None\n",
        "        rating = float(rating_element.text.strip()) if rating_element else None\n",
        "        author = author_element.text.strip() if author_element else None\n",
        "        date = date_element.text.strip() if date_element else None\n",
        "        body = body_element.text.strip() if body_element else None\n",
        "\n",
        "        review_info.append({\"title\": title, \"rating\": rating, \"author\": author, \"date\": date, \"body\": body})\n",
        "\n",
        "    return review_info\n",
        "\n",
        "def save_review_info_to_csv(review_info, filename):\n",
        "    with open(filename, \"w\", encoding=\"utf-8\", newline='') as f:\n",
        "        writer = csv.DictWriter(f, [\"title\", \"rating\", \"author\", \"date\", \"body\"])\n",
        "        writer.writeheader()\n",
        "        writer.writerows(review_info)\n",
        "\n",
        "def main(URL):\n",
        "    # Specifying user agent\n",
        "    HEADERS = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36',\n",
        "               'Accept-Language': 'en-US, en;q=0.5'}\n",
        "\n",
        "    # Making the HTTP Request\n",
        "    webpage = requests.get(URL, headers=HEADERS)\n",
        "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
        "\n",
        "    # Extract product information\n",
        "    title, price, rating, review_count, available = extract_product_info(soup)\n",
        "\n",
        "    # Save product information to a CSV file\n",
        "    with open(\"product_info.csv\", \"a\", encoding=\"utf-8\", newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([title, price, rating, review_count, available])\n",
        "\n",
        "    # Extract and save reviews to a CSV file\n",
        "    review_info = extract_reviews(soup)\n",
        "    save_review_info_to_csv(review_info, f\"reviews_product_{review_count}.csv\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # URLs to scrape\n",
        "    urls = [\n",
        "        \"https://www.amazon.com/Soundcore-Cancelling-Headphones-Comfortable-Bluetooth/dp/B08HMWZBXC/ref=sr_1_10?keywords=headphones&sr=8-10&th=1\",\n",
        "        \"https://www.amazon.com/dp/B0828PYKZN/ref=sspa_dk_detail_0?ie=UTF8&s=electronics&sp_csd=d2lkZ2V0TmFtZT1zcF9kZXRhaWxfdGhlbWF0aWM&pd_rd_i=B0828PYKZN&th=1\"\n",
        "    ]\n",
        "\n",
        "    # Iterating over the URLs\n",
        "    for url in urls:\n",
        "        main(url)\n"
      ],
      "metadata": {
        "id": "NK-sTqgSEjZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "def sentiment_analysis(text):\n",
        "    analysis = TextBlob(text)\n",
        "    return analysis.sentiment.polarity\n"
      ],
      "metadata": {
        "id": "G_oQZ9XEI513"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "def extract_keywords(text):\n",
        "    if isinstance(text, str):  # Check if text is a string\n",
        "        # Tokenize the text\n",
        "        words = word_tokenize(text)\n",
        "\n",
        "        # Remove stop words\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        filtered_words = [word.lower() for word in words if word.isalnum() and word.lower() not in stop_words]\n",
        "\n",
        "        # Perform frequency distribution\n",
        "        freq_dist = nltk.FreqDist(filtered_words)\n",
        "\n",
        "        # Get the top 3 keywords\n",
        "        top_keywords = freq_dist.most_common(3)\n",
        "\n",
        "        return [keyword[0] for keyword in top_keywords]\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3-03WfnJUVT",
        "outputId": "109ed15c-214b-43c4-8831-4c0df950467e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(text):\n",
        "    # Count the number of words\n",
        "    num_words = len(text.split())\n",
        "\n",
        "    # Count the number of characters\n",
        "    num_characters = len(text)\n",
        "\n",
        "    # Return a dictionary with extracted features\n",
        "    return {\n",
        "        'num_words': num_words,\n",
        "        'num_characters': num_characters,\n",
        "        # Add more features as needed\n",
        "    }\n"
      ],
      "metadata": {
        "id": "nOcG5qpQKjer"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def extract_features(text):\n",
        "    if isinstance(text, str) and not math.isnan(text):\n",
        "        # Count the number of words\n",
        "        num_words = len(text.split())\n",
        "\n",
        "        # Count the number of characters\n",
        "        num_characters = len(text)\n",
        "\n",
        "        # Return a dictionary with extracted features\n",
        "        return {\n",
        "            'num_words': num_words,\n",
        "            'num_characters': num_characters,\n",
        "            # Add more features as needed\n",
        "        }\n",
        "    else:\n",
        "        # Return a default dictionary for NaN values\n",
        "        return {\n",
        "            'num_words': 0,\n",
        "            'num_characters': 0,\n",
        "        }\n"
      ],
      "metadata": {
        "id": "zStpGhPWKzxr"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read review data from CSV files\n",
        "product_1_reviews = pd.read_csv(\"/content/reviews_product_60337 ratings.csv\")\n",
        "product_2_reviews = pd.read_csv(\"/content/reviews_product_69060 ratings.csv\")\n",
        "\n",
        "# Analyze average rating\n",
        "avg_rating_1 = product_1_reviews[\"rating\"].mean()\n",
        "avg_rating_2 = product_2_reviews[\"rating\"].mean()\n",
        "\n",
        "# Analyze sentiment\n",
        "sentiment_1 = product_1_reviews[\"body\"].fillna(\"\").apply(sentiment_analysis)\n",
        "sentiment_2 = product_2_reviews[\"body\"].fillna(\"\").apply(sentiment_analysis)\n",
        "\n",
        "\n",
        "# Analyze common keywords\n",
        "keywords_1 = product_1_reviews[\"body\"].apply(extract_keywords)\n",
        "keywords_2 = product_2_reviews[\"body\"].apply(extract_keywords)\n",
        "\n",
        "# Compare product features\n",
        "product_1_features = []\n",
        "product_2_features = []\n",
        "\n",
        "for review in product_1_reviews[\"body\"]:\n",
        "    product_1_features.append(extract_features(review))\n",
        "\n",
        "for review in product_2_reviews[\"body\"]:\n",
        "    product_2_features.append(extract_features(review))\n",
        "\n"
      ],
      "metadata": {
        "id": "RLMX54pwHgRr"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}